swirl()
install_from_swirl("Regression Models")
swirl()
rm(list = ls())
library(swirl)
swirl()
plot(child ~ parent, galton)
plot(jitter(child, 4) ~ parent, galton)
regrline <- lm(child ~ parent, galton)
abline(regrline, lwd = 3, col = "red")
summary(regrline)
fit <- lm(child ~ parent, galton)
summary(fit)
mean(fit$residuals)
cov(fit$residuals, galton$parent)
ols.ic <- fit$coef[1]
ols.slope <- fit$coef[2]
lhs - rhs
all.equal(lhs, rhs)
varChild <- var(galton$children)
head(galton)
varChild <- var(galton$child)
varRes <- var(fit$residuals)
varEst <- var(fit$fitted)
varEst <- var(est(ols.slope, ols.ic))
all.equal(varChild, varRes + varEst)
efit <- lm(accel ~ mag + dist, attenu)
mean(efit$residuals)
cov(efit$residuals, attenu$mag)
cov(efit$residuals, attenu$dist)
rm(list = ls())
swirl()
library(swirl)
library(swirl)
swirl()
cor(gpa_nor, gch_nor)
l_nor <- lm(gch_nor ~ gpa_nor)
fit <- lm(child ~ parent, galton)
sum(fit$residuals) / (n-2)
sqrt(sum(fit$residuals) / (n-2))
sqrt(sum(fit$residuals^2) / (n-2))
summary(fit)$sigma
sqrt(deviance(fit)/(n-2))
mu = mean(gch)
mu <- mean(galton$child)
sTot <- sum((galton$child - mean(galton$child))^2)
sTot <- sum((galton$child - mu)^2)
sRes <- deviance(fit)
1 - sRes/sTot
summary(fit)$r.squared
?cor
cor(gch, gpa)
cor(galton$parent,galton$child)^2
rm(list = ls())
library(swirl)
swirl()
ones <- rep(1, nrow(galton))
lm(child ~ ones + parent - 1, galton)
lm(child ~ parent, galton)
lm(child ~ 1, galton)
head(trees)
fit <- lm(Volume ~ Girth + Height + Constant -1, trees)
trees2 <- eliminate("Girth", trees)
head(trees2)
fit2 <- lm(Volume ~ Height
| + Constant -1, trees2)
fit2 <- lm(Volume ~ Height + Constant -1, trees2)
lapply(list(fit, fit2), coef)
rm(list = ls())
library(swirl)
swirl()
lm(Fertility ~ ., swiss)
all <- lm(Fertility ~ ., swiss)
summary(all)
lm(Fertility ~ Agriculture, swiss)
summary(lm(Fertility ~ Agriculture, swiss))
cor(swiss$Examination, swiss$Education)
cor(swiss$Agriculture, swiss$Education)
makelms()
ec <- swiss$Examination + swiss$Catholic
efit <- lm(Fertility ~ . + ec, swiss)
summary(efit)
all$coefficients-efit$coefficients
library(swirl)
swirl()
all <- lm(Fertility ~ ., swiss)
summary(all)
lm(Fertility ~ Agriculture, swiss)
summary(lm(Fertility ~ Agriculture, swiss))
cor(swiss$Examination, swiss$Education)
cor(swiss$Agriculture, swiss$Education)
makelms()
ec <- swiss$Examination + swiss$Catholic
efit <- lm(Fertility ~ . + ec, swiss)
all$coefficients-efit$coefficients
6
quit()
info()
byw()
bye()
rm(list = ls())
swirl()
dim(InsectSprays)
head(InsectSprays, 15)
sA
summary(InsectSprays[,2])
sapply(InsectSprays, class)
fit <- lm(count ~ spray, InsectSprays)
fit$coef
summary(fit)$coef
est <- summary(fit)$coef[,1]
mean(sA)
mean(sB)
nfit <- lm(count ~ spray - 1, InsectSprays)
summary(nfit)$coef
spray2 <- relevel(InsectSprays$spray, "C")
spray2
fit2 <- lm(count ~ spray2, InsectSprays)
summary(fit2)$coef
mean(sC)
(fit$coef[3] - fit$coef[2]) / 1.6011
(fit$coef[2] - fit$coef[3]) / 1.6011
dim(hunger)
948
names(hunger)
fit <- lm(Numeric ~ Year, hunger)
summary(fit)$coef
lmF <- lm(Numeric ~ Year, hunger[hunger$Sex=="Female", ])
lmF <- lm(Numeric[Sex=="Female"] ~ Year[Sex=="Female"], hunger)
lmM <- lm(Numeric[Sex=="Male"] ~ Year[Sex=="Male"], hunger)
lmBoth <- lm(Numeric ~ Year + Sex, hunger)
summary(lmBoth)
lmInter <- lm(Numeric ~ Year + Sex + Sex*Year, hunger)
summary(lmBoth)
summary(lmInter)
rm(list = ls())
library(swirl)
swirl()
fit <- lm(y ~ x, out2)
plot(fit, which = 1)
fitno <- lm(y ~ x, out2[-1, ])
plot(fitno, which = 1)
coef(fit) - coef(fitno)
coef(fit)
coef(fitno)
head(dfbeta(fit))
resno <- out2[1, "y"] - predict(fitno, out2[1,])
1-resid(fit)[1]/resno
head(hatvalues(fit))
sigma <- deviance(fit) / 49
sigma <- sqrt(deviance(fit)/df.residual(fit))
df.residual(fit)
rstd <- resid(fit)/(sigma * sqrt(1-hatvalues(fit)))
head(cbind(rstd, rstandard(fit)))
plot(fit, which = 3)
plot(fit, which = 2)
sigma1 <- sqrt(deviance(fitno) / df.residuals(fitno))
sigma1 <- sqrt(deviance(fitno) / df.residual(fitno))
resid(fit)[1] / sqrt(1 - hatvalues(fit)[1])
resid(fit)[1]/(sigma1*sqrt(1-hatvalues(fit)[1]))
head(rstudent(fit))
dy <-  predict(fitno, out2) - predict(fit, out2)
sum(dy^2) / (2*sigma^2)
plot(fit, which = 5)
rm(list = ls())
library(swirl)
swirl()
fit <- lm(y ~ x, out2)
plot(fit, which = 1)
fitno <- lm(y ~ x, out2[-1, ])
plot(fitno, which = 1)
coef(fit) - coef(fitno)
head(dfbeta(fit))
resno <- out2[1, "y"] - predict(fitno, out2[1,])
1-resid(fit)[1]/resno
head(hatvalues(fit))
sigma <- sqrt(deviance(fit)/df.residual(fit))
rstd <- resid(fit)/(sigma * sqrt(1-hatvalues(fit)))
head(cbind(rstd, rstandard(fit)))
plot(fit, which = 3)
plot(fit, which = 2)
sigma1 <- sqrt(deviance(fitno) / df.residuals(fitno))
sigma1 <- sqrt(deviance(fitno) / df.residual(fitno))
resid(fit)[1]/(sigma1*sqrt(1-hatvalues(fit)[1]))
head(rstudent(fit))
dy <-  predict(fitno, out2) - predict(fit, out2)
sum(dy^2) / (2*sigma^2)
cooks.distance(fit)
plot(fit, which = 5)
rm(list = ls())
swirl()
rpg1()
rgp1()
1/sqrt(2)
rgp2()
heas(swiss)
head(swiss)
mdl <- lm(Fertility ~ ., swiss)
vif(mdl)
mdl2 <- lm(Fertility ~ . - Examination, swiss)
vif(mdl2)
rm(list = ls())
swirl()
x1c <- simbias()
apply(x1c, 1, mean)
fit1 <- lm(Fertility ~ Agriculture, swiss)
fit3 <- lm(Fertility ~ Agriculture + Examination + Education, swiss)
anova(fit1, fit3)
rm(list = ls())
library(swirl)
swirl()
swirl()
swirl()
swirl()
x1c <- simbias()
quit()
info()
bye()
swirl()
apply(x1c, 1, mean)
fit1 <- lm(Fertility ~ Agriculture, swiss)
fit3 <- lm(Fertility ~ Agriculture + Examination + Education, swiss)
anova(fit1, fit3)
deviance(fit3)
d <- deviance(fit3) / 43
n <- (deviance(fit1) - deviance(fit3)) / 2
n/d
pf(n/d, 2, 43, lower.tail = FALSE)
shapiro.test(fit3$residuals)
anova(fit1, fit3, fit5, fit6)
rm(list = ls())
rm(list = ls())
library(swirl)
swirl()
ravenData
mdl <- glm(ravenWinNum ~ ravenScore, "binomial", ravenData)
lodds <- predict(mdl, data.frame(ravenScore=c(0, 3, 6))
)
exp(lodds)/(1+exp(lodds))
summary(mdl)
exp(confint(mdl))
anova(mdl)
qchisq(0.95, 1)
mdl9 <- glm(ravenWinNum ~ 1, "binomial", ravenData)
summary(mdl0)
summary(mdl9)
exp(0.8473)
exp(0.8473) / (1 + exp(0.8473))
summary(ravenData)
14 / 20
rm(list = ls())
swirl()
x1c <- simbias()
apply(x1c, 1, mean)
fit1 <- lm(Fertility ~ Agriculture, swiss)
fit3 <- lm(Fertility ~ Agriculture + Examination + Education, swiss)
anova(fit1, fit3)
deviance(fit3)
d <- deviance(fit3) / 43
n <- (deviance(fit1) - deviance(fit3)) / 2
n/d
pf(n/d, 2, 43, lower.tail = FALSE)
shapiro.test(fit3$residuals)
anova(fit1, fit3, fit5, fit6)
rm(list = ls())
swirl()
var(rpois(1000, 50))
nxt()
head(hits)
class(hits[,"date"])
as.integer(head(hits[,"date"]))
bye()
rm(list = ls())
library("caret", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
(0.99*0.001) / ((0.99*0.001) + (0.01 * 0.999))
data(faithful)
describe(faithful)
nearZeroVar(faithful$waiting)
nearZeroVar(faithful)
?embed
x <- 1:10
embed (x, 3)
rm(list = ls())
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
library("AppliedPredictiveModeling", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[trainIndex,]
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[trainIndex,]
rm(list = ls())
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
names(training)
names(concrete)
names(mixtures)
library(ggplot2)
qplot(1:1030, CompressiveStrength, data = training)
qplot(seq_along(training), CompressiveStrength, data = training)
seq_along(training)
qplot(1:nrow(training), CompressiveStrength, data = training)
str(training)
qplot(1:nrow(training), CompressiveStrength, data = training, colour = Cement)
qplot(1:nrow(training), CompressiveStrength, data = training, colour = FlyAsh)
qplot(1:nrow(training), CompressiveStrength, data = training, colour = Age)
qplot(1:nrow(training), CompressiveStrength, data = training, colour = FlyAsh)
qplot(1:nrow(training), CompressiveStrength, data = training, colour = Water)
rm(list = ls())
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
names(training)
qplot(Superplasticizer, data = training)
qplot(Superplasticizer, data = training, binwidth = x)
qplot(Superplasticizer, data = training, binwidth = 5)
qplot(Superplasticizer, data = training, binwidth = 1)
qplot(Superplasticizer, data = training, binwidth = 0.01)
qplot(Superplasticizer, data = training, binwidth = 0.00001)
qplot(Superplasticizer, data = training, binwidth = 0.0001)
qplot(Superplasticizer, data = training, binwidth = 0.001)
summary(training$Superplasticizer)
qplot(log(Superplasticizer), data = training, binwidth = 0.001)
qplot(log(Superplasticizer), data = training)
qplot(log(Superplasticizer+1), data = training)
rm(list = ls())
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
names(training)
?grep
selection <- grep("IL", names(training))
selection
data <- training[, c(58:69)]
?preProcess
preObj <- preProcess(data, method = "pca")
preObj
preObj <- preProcess(data, method = "pca", pcaComp = 9)
preObj
preObj <- preProcess(data, method = "pca", thresh = 0.8)
preObj
rm(list = ls())
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
train <- training[, c(58:69)]
names(train)
test <- testing[, c(58:69)]
names(test)
names(training)
train <- training[, c(1, 58:69)]
test <- testing[, c(1, 58:69)]
fit1 <- train(diagnosis ~ ., data = train, method = "glm")
?train
fit1 <- train(diagnosis ~ ., data = train, method = "glm")
install.packages("e1071")
fit1 <- train(diagnosis ~ ., data = train, method = "glm")
fit1
names(train)
fit1
preObj <- preProcess(train, method = "pca", thresh = 0.8)
preObj <- preProcess(train[ , -1], method = "pca", thresh = 0.8)
rm(list = ls())
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
training <- training[, c(1, 58:69)]
testing <- testing[, c(1, 58:69)]
fit1 <- train(diagnosis ~ ., data = training, method = "glm")
prediction <- predict(fit1, newdata = testing)
head(prediction)
head(training$diagnosis)
table(prediction, testing$diagnosis)
(51+2)/(51+2+20+9)
preObj <- preProcess(training[ , -1], method = "pca", thresh = 0.8)
pcaTraining <- predict(preObj, training)
pcaTraining <- predict(preObj, training[ , -1])
fit2 <- train(training$diagnosis ~ ., data = pcaTraining, method = "glm")
fit2
prediction2 <- predict(fit2, newdata = predict(preObj, testing[ , -1]))
table(prediction2, testing$diagnosis)
(56+3)/(3+56+19+4)
library(rCharts)
names(iris) = gsub("\\.", "", names(iris))
rPlot(SepalLength ~ SepalWidth | Species, data = iris, color = 'Species', type = 'point')
hair_eye_male <- subset(as.data.frame(HairEyeColor), Sex == "Male")
n1 <- nPlot(Freq ~ Hair, group = "Eye", data = hair_eye_male, type = "multiBarChart")
n1$print("chart3")
data(economics, package = "ggplot2")
econ <- transform(economics, date = as.character(date))
m1 <- mPlot(x = "date", y = c("psavert", "uempmed"), type = "Line", data = econ)
m1$set(pointSize = 0, lineWidth = 1)
m1$print("chart2")
data(economics, package = "ggplot2")
econ <- transform(economics, date = as.character(date))
m1 <- mPlot(x = "date", y = c("psavert", "uempmed"), type = "Line", data = econ)
m1$set(pointSize = 0, lineWidth = 1)
m1$print("chart2")
m1
n1
libary(manipulate)
library(manipulate)
manipulate(plot(1:x), x = slider(1, 100))
install.packages("shinytools")
install.packages("shinyapps")
library(devtools)
install.packages("shinyapps")
devtools::install_github('rstudio/shinyapps')
shinyapps::setAccountInfo(name='jroberayalas', token='B522C2849E2E77BF45DEAEAFCE194DC2', secret='dxKBqKC0XqSm5e/Y5ux3d5p0T4pu3yUiVpV8ORX7')
library(plotly)
rm(list = ls())
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
with(cars, plot(dist, speed))
with(cars, plot(dist - mean(dist), speed - mean(speed)))
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
library(rCharts)
data(airquality)
dTable(airquality, sPaginationType = "full_numbers")
library(devtools)
library(slidify)
library(caret)
?train
setwd("~/Desktop/Academico/Coursera/Data Science Specialization/08 Practical Machine Learning/Project")
rm(list = ls())
dataset <- read.csv("pml-training.csv", na.strings = c("NA", "", " "))
19622/6
names(dataset)
complete.cases(dataset)
sum(!complete.cases(dataset))
names(dataset)
160-107
dataset <- read.csv("pml-training.csv", na.strings = c("NA", "", " "))
# Check for NAs
sum(!complete.cases(dataset))
summary(dataset)
# Omit columns with NAs
omit.variables <- sapply(dataset, function(x) {sum(is.na(x)) > 0})
dataset <- dataset[ , !omit.variables]
# Omit first columns (no useful info)
library(dplyr)
dataset <- select(dataset, -(X:num_window))
qplot(classe, data = training, colour = classe)
# Read data
dataset <- read.csv("pml-training.csv", na.strings = c("NA", "", " "))
# Check for NAs
sum(!complete.cases(dataset))
summary(dataset)
# Omit columns with NAs
omit.variables <- sapply(dataset, function(x) {sum(is.na(x)) > 0})
dataset <- dataset[ , !omit.variables]
# Omit first columns (no useful info)
library(dplyr)
dataset <- select(dataset, -(X:num_window))
# Create training and test set
library(caret)
set.seed(12321)
inTrain <- createDataPartition(dataset$classe, p = 0.7, list = FALSE)
training <- dataset[inTrain, ]
testing <- dataset[-inTrain, ]
# Plot
qplot(classe, data = training, colour = classe)
qplot(classe, data = training, fill = classe)
names(training)
qplot(roll_belt, data = training, color = classe)
head(training$roll_belt)
qplot(1:13737, roll_belt, data = training, color = classe)
qplot(1:13737, pitch_belt, data = training, color = classe)
qplot(1:13737, yaw_belt, data = training, color = classe)
fit <- train(classe~., data = training, method ="rpart")
plot(fit$finalModel)
text(fit$finalModel)
qplot(1:13737, pitch_forearm, data = training, color = classe)
